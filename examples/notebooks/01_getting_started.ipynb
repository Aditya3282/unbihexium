{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unbihexium: Complete Getting Started Guide\n",
                "\n",
                "[![CI](https://github.com/unbihexium-oss/unbihexium/workflows/CI/badge.svg)](https://github.com/unbihexium-oss/unbihexium/actions)\n",
                "[![PyPI](https://img.shields.io/pypi/v/unbihexium.svg)](https://pypi.org/project/unbihexium/)\n",
                "[![License](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](https://github.com/unbihexium-oss/unbihexium/blob/main/LICENSE.txt)\n",
                "[![Models](https://img.shields.io/badge/models-390-orange.svg)](https://github.com/unbihexium-oss/unbihexium/tree/main/model_zoo)\n",
                "\n",
                "**Author**: Unbihexium OSS Foundation  \n",
                "**Version**: 1.0.0  \n",
                "**Last Updated**: 2025-12-19\n",
                "\n",
                "---\n",
                "\n",
                "## Purpose\n",
                "\n",
                "This notebook provides a comprehensive introduction to the Unbihexium geospatial AI library, covering installation, model zoo exploration, and basic inference workflows.\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Python 3.10+\n",
                "- pip or conda\n",
                "- 8GB RAM minimum"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "\n",
                "Install Unbihexium using pip:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install unbihexium (uncomment to run)\n",
                "# !pip install unbihexium"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Verify Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "print(f\"Python version: {sys.version}\")\n",
                "\n",
                "# Check if unbihexium is available\n",
                "try:\n",
                "    import unbihexium\n",
                "    print(f\"Unbihexium version: {unbihexium.__version__}\")\n",
                "except ImportError:\n",
                "    print(\"Unbihexium not installed. Please run: pip install unbihexium\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Explore Model Zoo\n",
                "\n",
                "The model zoo contains 130 models with 3 variants each (tiny, base, large) = 390 total.\n",
                "\n",
                "| Variant | Resolution | Use Case |\n",
                "|---------|------------|----------|\n",
                "| tiny | 32x32 | Testing, edge devices |\n",
                "| base | 64x64 | Production |\n",
                "| large | 128x128 | High accuracy |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import yaml\n",
                "\n",
                "# Load model inventory\n",
                "inventory_path = Path(\"../model_zoo/inventory.yaml\")\n",
                "if inventory_path.exists():\n",
                "    with open(inventory_path) as f:\n",
                "        inventory = yaml.safe_load(f)\n",
                "    models = inventory.get(\"models\", [])\n",
                "    print(f\"Total models in inventory: {len(models)}\")\n",
                "    print(f\"Total variants: {len(models) * 3}\")\n",
                "    \n",
                "    # Show first 5 models\n",
                "    print(\"\\nSample models:\")\n",
                "    for m in models[:5]:\n",
                "        print(f\"  - {m['model_id']}: {m['name']} ({m['task']})\")\n",
                "else:\n",
                "    print(\"Run from repository root or adjust path.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load and Run ONNX Model\n",
                "\n",
                "Models are stored as ONNX files for cross-platform inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "try:\n",
                "    import onnxruntime as ort\n",
                "    \n",
                "    # Load a tiny model for testing\n",
                "    model_path = Path(\"../model_zoo/assets/tiny/ship_detector_tiny/model.onnx\")\n",
                "    if model_path.exists():\n",
                "        session = ort.InferenceSession(str(model_path))\n",
                "        \n",
                "        # Get input details\n",
                "        input_info = session.get_inputs()[0]\n",
                "        print(f\"Input name: {input_info.name}\")\n",
                "        print(f\"Input shape: {input_info.shape}\")\n",
                "        print(f\"Input type: {input_info.type}\")\n",
                "        \n",
                "        # Create dummy input and run inference\n",
                "        dummy_input = np.random.rand(1, 3, 32, 32).astype(np.float32)\n",
                "        outputs = session.run(None, {input_info.name: dummy_input})\n",
                "        \n",
                "        print(f\"\\nOutput shape: {outputs[0].shape}\")\n",
                "        print(\"Inference successful!\")\n",
                "    else:\n",
                "        print(f\"Model not found at {model_path}\")\n",
                "except ImportError:\n",
                "    print(\"Install onnxruntime: pip install onnxruntime\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Categories\n",
                "\n",
                "Models are organized by task:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import Counter\n",
                "\n",
                "if 'models' in dir():\n",
                "    tasks = Counter(m['task'] for m in models)\n",
                "    print(\"Models by task:\")\n",
                "    for task, count in tasks.most_common():\n",
                "        print(f\"  {task}: {count} models ({count * 3} variants)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Next Steps\n",
                "\n",
                "- Explore [Object Detection Notebook](02_object_detection.ipynb)\n",
                "- Learn about [Spectral Indices](03_spectral_indices.ipynb)\n",
                "- Try [Change Detection](04_change_detection.ipynb)\n",
                "\n",
                "---\n",
                "\n",
                "**Copyright 2025 Unbihexium OSS Foundation. Apache-2.0 License.**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}